{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-13T16:21:21.889870300Z",
     "start_time": "2025-05-13T16:21:21.851615200Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_movies.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-13T16:21:21.915627800Z",
     "start_time": "2025-05-13T16:21:21.856557400Z"
    }
   },
   "id": "508353d531c3742a",
   "execution_count": 99
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "budget              int64\n",
      "runtime           float64\n",
      "vote_average      float64\n",
      "vote_count          int64\n",
      "revenue             int64\n",
      "release_year        int64\n",
      "genres_score      float64\n",
      "language_score    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['genres', 'original_language', 'popularity_class', 'popularity']).copy()\n",
    "y = df['popularity_class']\n",
    "print(X.dtypes)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-13T16:21:21.927829700Z",
     "start_time": "2025-05-13T16:21:21.872794Z"
    }
   },
   "id": "a17961405b7f8569",
   "execution_count": 100
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SVM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93b479ab93c738bf"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Acc: 0.9021 | Prec: 0.8548 | Rec: 0.7709 | F1: 0.8024\n",
      "Fold 2 - Acc: 0.8927 | Prec: 0.8141 | Rec: 0.7281 | F1: 0.7583\n",
      "Fold 3 - Acc: 0.9219 | Prec: 0.8450 | Rec: 0.8289 | F1: 0.8366\n",
      "Fold 4 - Acc: 0.9042 | Prec: 0.8116 | Rec: 0.7467 | F1: 0.7728\n",
      "Fold 5 - Acc: 0.9167 | Prec: 0.9188 | Rec: 0.7940 | F1: 0.8399\n",
      "\n",
      "--- Summary ---\n",
      "Mean Accuracy: 0.9075\n",
      "Mean Precision: 0.8489\n",
      "Mean Recall: 0.7737\n",
      "Mean F1-score: 0.8020\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svc', SVC())\n",
    "])\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 5-fold cross-validation\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "\n",
    "    accuracies.append(acc)\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "    f1s.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold+1} - Acc: {acc:.4f} | Prec: {prec:.4f} | Rec: {rec:.4f} | F1: {f1:.4f}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Summary ---\")\n",
    "print(f\"Mean Accuracy: {np.mean(accuracies):.4f}\")\n",
    "print(f\"Mean Precision: {np.mean(precisions):.4f}\")\n",
    "print(f\"Mean Recall: {np.mean(recalls):.4f}\")\n",
    "print(f\"Mean F1-score: {np.mean(f1s):.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-13T16:21:22.684676400Z",
     "start_time": "2025-05-13T16:21:21.884574800Z"
    }
   },
   "id": "5a3894585c82a9f1",
   "execution_count": 101
  },
  {
   "cell_type": "markdown",
   "source": [
    "# KNN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e38d40618f1fc38e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Acc: 0.8604 | Prec: 0.7965 | Rec: 0.7347 | F1: 0.7604\n",
      "Fold 2 - Acc: 0.8667 | Prec: 0.8123 | Rec: 0.7239 | F1: 0.7561\n",
      "Fold 3 - Acc: 0.8802 | Prec: 0.8507 | Rec: 0.7546 | F1: 0.7931\n",
      "Fold 4 - Acc: 0.8583 | Prec: 0.8183 | Rec: 0.6991 | F1: 0.7399\n",
      "Fold 5 - Acc: 0.8823 | Prec: 0.8654 | Rec: 0.7619 | F1: 0.8028\n",
      "\n",
      "--- Summary ---\n",
      "Mean Accuracy: 0.8696\n",
      "Mean Precision: 0.8286\n",
      "Mean Recall: 0.7348\n",
      "Mean F1-score: 0.7704\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5))\n",
    "])\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 5-fold cross-validation\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "\n",
    "    accuracies.append(acc)\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "    f1s.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold+1} - Acc: {acc:.4f} | Prec: {prec:.4f} | Rec: {rec:.4f} | F1: {f1:.4f}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Summary ---\")\n",
    "print(f\"Mean Accuracy: {np.mean(accuracies):.4f}\")\n",
    "print(f\"Mean Precision: {np.mean(precisions):.4f}\")\n",
    "print(f\"Mean Recall: {np.mean(recalls):.4f}\")\n",
    "print(f\"Mean F1-score: {np.mean(f1s):.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-13T16:21:22.936655100Z",
     "start_time": "2025-05-13T16:21:22.684676400Z"
    }
   },
   "id": "d2cdb6bb512eead2",
   "execution_count": 102
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DECISION TREE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bc6c87ab3f35993"
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Acc: 0.8865 | Prec: 0.7916 | Rec: 0.7916 | F1: 0.7916\n",
      "Fold 2 - Acc: 0.8917 | Prec: 0.7944 | Rec: 0.8027 | F1: 0.7984\n",
      "Fold 3 - Acc: 0.8854 | Prec: 0.7602 | Rec: 0.8417 | F1: 0.7910\n",
      "Fold 4 - Acc: 0.8802 | Prec: 0.7566 | Rec: 0.7374 | F1: 0.7464\n",
      "Fold 5 - Acc: 0.8823 | Prec: 0.7902 | Rec: 0.7812 | F1: 0.7854\n",
      "\n",
      "--- Summary ---\n",
      "Mean Accuracy: 0.8852\n",
      "Mean Precision: 0.7786\n",
      "Mean Recall: 0.7909\n",
      "Mean F1-score: 0.7826\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tree', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# 5-fold cross-validation\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "\n",
    "    accuracies.append(acc)\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "    f1s.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold+1} - Acc: {acc:.4f} | Prec: {prec:.4f} | Rec: {rec:.4f} | F1: {f1:.4f}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Summary ---\")\n",
    "print(f\"Mean Accuracy: {np.mean(accuracies):.4f}\")\n",
    "print(f\"Mean Precision: {np.mean(precisions):.4f}\")\n",
    "print(f\"Mean Recall: {np.mean(recalls):.4f}\")\n",
    "print(f\"Mean F1-score: {np.mean(f1s):.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-13T16:21:23.044794400Z",
     "start_time": "2025-05-13T16:21:22.938598Z"
    }
   },
   "id": "bd6535a1ef8a6b74"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MULTILAYER PERCEPTRON (MLP)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2165c5c6acd94cc3"
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Acc: 0.9156 | Prec: 0.8692 | Rec: 0.8241 | F1: 0.8438\n",
      "Fold 2 - Acc: 0.8938 | Prec: 0.8094 | Rec: 0.7561 | F1: 0.7772\n",
      "Fold 3 - Acc: 0.9240 | Prec: 0.8258 | Rec: 0.8060 | F1: 0.8154\n",
      "Fold 4 - Acc: 0.9094 | Prec: 0.8026 | Rec: 0.8018 | F1: 0.8022\n",
      "Fold 5 - Acc: 0.9208 | Prec: 0.9356 | Rec: 0.8131 | F1: 0.8569\n",
      "\n",
      "--- Summary ---\n",
      "Mean Accuracy: 0.9127\n",
      "Mean Precision: 0.8485\n",
      "Mean Recall: 0.8002\n",
      "Mean F1-score: 0.8191\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(100, 50),     # two hidden layers: 100 and 50 neurons\n",
    "    activation='relu',                # a commonly used activation function\n",
    "    solver='adam',                    # modern optimizer, better than 'sgd' in most cases\n",
    "    learning_rate_init=0.001,         # lower learning rate improves stability\n",
    "    max_iter=1000,                    # more iterations to allow convergence\n",
    "    early_stopping=True,              # stops training if validation score doesn't improve\n",
    "    random_state=42                   # ensures reproducibility\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('mlp', mlp)\n",
    "])\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# 5-fold cross-validation\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "\n",
    "    accuracies.append(acc)\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "    f1s.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold+1} - Acc: {acc:.4f} | Prec: {prec:.4f} | Rec: {rec:.4f} | F1: {f1:.4f}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Summary ---\")\n",
    "print(f\"Mean Accuracy: {np.mean(accuracies):.4f}\")\n",
    "print(f\"Mean Precision: {np.mean(precisions):.4f}\")\n",
    "print(f\"Mean Recall: {np.mean(recalls):.4f}\")\n",
    "print(f\"Mean F1-score: {np.mean(f1s):.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-13T16:21:26.859745800Z",
     "start_time": "2025-05-13T16:21:23.048912500Z"
    }
   },
   "id": "d200e8c23d9f20f3"
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-13T16:21:26.859745800Z",
     "start_time": "2025-05-13T16:21:26.857990900Z"
    }
   },
   "id": "f36f5bddc2e1c17c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
